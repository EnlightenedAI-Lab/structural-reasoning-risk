<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>How It Works · Reflective Diagnostics</title>
  <meta name="description" content="Replayable measurement pipeline for structural reasoning risk with auditable, deterministic artifacts." />
  <link rel="stylesheet" href="assets/site.css" />
</head>

<body>
  <!-- Top Nav -->
  <div class="topbar">
    <div class="topbar-inner">
      <div class="brand">
        <div class="t">Reflective Diagnostics™</div>
        <div class="s">Structural Reasoning Risk · restricted evaluation · auditable diagnostics</div>
      </div>

      <div class="nav">
        <a href="index.html">Start Here</a>
        <a class="active" href="how-it-works.html">How It Works</a>
        <a href="what-it-measures.html">What It Measures</a>
        <a href="use-cases.html">Use Cases and Value</a>
        <a href="evidence.html">Proof and Evidence</a>
        <a href="funding-roadmap.html">Funding and Roadmap</a>
        <a href="compliance.html">Compliance</a>
      </div>
    </div>
  </div>

  <div class="wrap">
    <!-- HERO -->
    <section class="hero">
      <div class="kickers">
        <div class="pill accent">Research Prototype v1.0</div>
        <div class="pill">Deterministic Artifacts</div>
        <div class="pill">Cross Model Comparison</div>
        <div class="pill">Evidence Locked</div>
      </div>

      <h1>How it works: a replayable measurement pipeline — not “LLM as judge.”</h1>

      <p class="subtitle">
        Reflective Diagnostics evaluates <b>whether conclusions are structurally supported</b> by their stated premises.
        It converts model outputs into an inspectable support structure, computes structural signals,
        and produces a replayable evidence record suitable for audit and review.
      </p>

      <div class="btnrow">
        <a class="btn primary black" href="evidence.html">Open Proof and Evidence</a>
        <a class="btn" href="what-it-measures.html">Read Metric Definitions</a>
        <a class="btn" href="compliance.html">See Regime Mapping (Compliance)</a>
      </div>
    </section>

    <!-- PIPELINE OVERVIEW -->
    <section class="grid">
      <div class="card">
        <h2>End-to-End Measurement Flow</h2>
        <p class="mono">
          Input → Controlled Run → Artifact Capture → Structural Extraction → Signal Computation → Interpreter → Evidence Packet
        </p>
        <div class="callout">
          Each stage produces a fixed artifact that becomes the input to the next stage.
          No hidden rewrites. No silent retries.
        </div>
      </div>
    </section>

    <!-- STEPS -->
    <section class="grid">
      <div class="card">
        <h2>1) Controlled Run (Comparability)</h2>
        <ul>
          <li>Same input and constraints across models</li>
          <li>No hidden retries, no prompt rewriting, no adaptive steering</li>
          <li>Model identity and version recorded</li>
        </ul>
        <div class="callout">
          Why it matters: observed differences are attributable to the model, not shifting conditions.
        </div>
      </div>

      <div class="card">
        <h2>2) Artifact Capture (Source of Record)</h2>
        <ul>
          <li>Raw model outputs stored verbatim</li>
          <li>Run metadata captured (timestamps, run ID, model selection)</li>
          <li>Hashes generated to prevent silent alteration</li>
        </ul>
        <div class="callout">
          Why it matters: a run can be audited by someone who did not witness it.
        </div>
      </div>

      <div class="card">
        <h2>3) Structural Extraction (Support Graph)</h2>
        <ul>
          <li>Claims, premises, and conclusions explicitly identified</li>
          <li>Support links established between premises and conclusions</li>
          <li>Unsupported conclusions (orphans) flagged</li>
        </ul>
        <div class="callout">
          Why it matters: the instrument evaluates support structure, not writing quality.
        </div>
      </div>

      <div class="card">
        <h2>4) Signal Computation and Interpretation</h2>
        <ul>
          <li>Structural signals computed (coverage, orphan rate, integrity, stability)</li>
          <li>Cross-model divergence measured under identical constraints</li>
          <li>Interpreter produces a consolidated, inspectable synthesis</li>
        </ul>
        <div class="callout">
          Why it matters: evaluators can see where conclusions are structurally justified — and where they are not.
        </div>
      </div>
    </section>

    <!-- NON-GOALS -->
    <section class="grid">
      <div class="card">
        <h2>What This Instrument Does Not Do</h2>
        <ul>
          <li>It does not verify factual truth</li>
          <li>It does not score sentiment or policy merit</li>
          <li>It does not rely on subjective rubric grading</li>
        </ul>
        <div class="callout">
          The goal is <b>derivability</b>: can the conclusion be shown to follow from the stated premises?
        </div>
      </div>
    </section>

    <div class="footer">
      <div>Contact: <span class="mono">research@enlightenedai.ai</span></div>
      <div class="mono">Build: Research Prototype v1.0 · Reflective Diagnostics™ · restricted evaluation</div>
    </div>
  </div>
</body>
</html>
